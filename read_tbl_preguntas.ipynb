{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TBL Preguntas CSV Reader - Robust Parser âœ…\n",
    "\n",
    "This notebook reads the `tbl_preguntas.csv` file which has **malformed CSV structure** where the 'respuesta' column contains:\n",
    "- Unescaped newlines within quoted fields\n",
    "- CSV-escaped quotes (doubled quotes: `\"\"`)\n",
    "- Very long text content spanning many lines\n",
    "\n",
    "## The Problem\n",
    "- Standard CSV parsers fail because fields like `respuesta` have quotes that start but contain literal newlines\n",
    "- Records like ID **588, 595, 5475, 5181** span multiple lines and break normal parsing\n",
    "- Some fields contain escaped quotes using the CSV convention of doubling them\n",
    "\n",
    "## The Solution\n",
    "We use a **character-by-character state machine parser** that:\n",
    "1. Tracks whether we're inside or outside quoted fields\n",
    "2. Properly handles CSV-escaped quotes (`\"\"` â†’ `\"`)\n",
    "3. Accumulates multiline content within quotes\n",
    "4. Validates complete records (18 columns expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom CSV Parser Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_csv_with_multiline_fields(file_path):\n",
    "    \"\"\"\n",
    "    Parse CSV file that has newlines within quoted fields.\n",
    "    Handles CSV-escaped quotes (doubled quotes: \"\").\n",
    "    \n",
    "    Uses a character-by-character state machine approach:\n",
    "    - Tracks quote state to know when we're inside/outside quoted fields\n",
    "    - Handles escaped quotes (\"\" becomes \")\n",
    "    - Accumulates lines until complete record is found\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    current_record = []\n",
    "    current_field = []\n",
    "    in_quotes = False\n",
    "    header = None\n",
    "    prev_char = ''\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        char_iter = iter(lambda: f.read(1), '')\n",
    "\n",
    "        for char in char_iter:\n",
    "            if char == '\"':\n",
    "                # Check if this is an escaped quote (doubled: \"\")\n",
    "                if prev_char == '\"' and in_quotes:\n",
    "                    # This is an escaped quote - add one quote to field\n",
    "                    current_field.append('\"')\n",
    "                    prev_char = ''  # Reset to avoid triple-quote issues\n",
    "                    continue\n",
    "                else:\n",
    "                    # Toggle quote state\n",
    "                    in_quotes = not in_quotes\n",
    "                    prev_char = char\n",
    "                    continue\n",
    "\n",
    "            if not in_quotes:\n",
    "                if char == ',':\n",
    "                    # End of field\n",
    "                    current_record.append(''.join(current_field))\n",
    "                    current_field = []\n",
    "                elif char == '\\n':\n",
    "                    # End of record\n",
    "                    if current_field or current_record:\n",
    "                        current_record.append(''.join(current_field))\n",
    "                        current_field = []\n",
    "\n",
    "                        if header is None:\n",
    "                            header = current_record\n",
    "                        else:\n",
    "                            if len(current_record) == len(header):\n",
    "                                records.append(current_record)\n",
    "                        current_record = []\n",
    "                else:\n",
    "                    current_field.append(char)\n",
    "            else:\n",
    "                # Inside quotes - add everything including newlines\n",
    "                current_field.append(char)\n",
    "\n",
    "            prev_char = char\n",
    "\n",
    "        # Handle last field/record\n",
    "        if current_field or current_record:\n",
    "            current_record.append(''.join(current_field))\n",
    "            if len(current_record) == len(header):\n",
    "                records.append(current_record)\n",
    "\n",
    "    df = pd.DataFrame(records, columns=header)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tbl_preguntas.csv with custom parser...\n",
      "This may take a moment...\n",
      "\n",
      "âœ… Successfully loaded 1,489 records\n",
      "\n",
      "Columns (18): ['idtbl_pregunta', 'titulo', 'respuesta', 'id_usuario_creador', 'fecha_creacion', 'id_usuario_ultima_modificacion', 'fecha_ultima_modificacion', 'id_producto', 'id_estado', 'fecha_ult_actualizacion_keywords', 'keywords_rag', 'Vigencia', 'estado_carga', 'dias_vigencia', 'justificacion_garante', 'justificacion_curador', 'publicado_workplace', 'fecha_publicacion']\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading tbl_preguntas.csv with custom parser...\")\n",
    "print(\"This may take a moment...\\n\")\n",
    "\n",
    "df = parse_csv_with_multiline_fields('tbl_preguntas.csv')\n",
    "\n",
    "print(f\"âœ… Successfully loaded {len(df):,} records\")\n",
    "print(f\"\\nColumns ({len(df.columns)}): {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Converted numeric columns\n"
     ]
    }
   ],
   "source": [
    "# Convert numeric columns to proper types\n",
    "numeric_cols = ['idtbl_pregunta', 'id_usuario_creador', 'id_usuario_ultima_modificacion',\n",
    "                'id_producto', 'id_estado', 'estado_carga', 'dias_vigencia']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "print(\"âœ… Converted numeric columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Verify Problematic Records\n",
    "\n",
    "Let's check the specific IDs you mentioned that had parsing issues: **588, 595, 5475, 5181**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "VERIFICATION OF PROBLEMATIC RECORDS\n",
      "====================================================================================================\n",
      "\n",
      "âœ… ID 588 FOUND\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Titulo: Â¿QuÃ© aspectos debo tener en cuenta para efectuar un ajuste por concepto de: GMF 4X1000, BRP, Uso de RPD y Egreso 25?\n",
      "\n",
      "Respuesta stats:\n",
      "  - Length: 6,066 characters\n",
      "  - Newlines: 62\n",
      "  - Contains quotes: No\n",
      "\n",
      "First 300 chars of respuesta:\n",
      "GMF: Recordemos que todos los ajustes por GMF (4X1000) deben contar con el VoBo del Dpto de impuestos.Si el ajuste solicitado es autorizado la instrucciÃ³n del proceso, es decir, los conceptos y la forma en que se debe efectuar la transacciÃ³n de ajuste serÃ¡ dada por el dpto de impuestos exclusivament\n",
      "...\n",
      "\n",
      "âœ… ID 595 FOUND\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Titulo: Â¿QuÃ© es mi informaciÃ³n confidencial?\n",
      "\n",
      "Respuesta stats:\n",
      "  - Length: 2,949 characters\n",
      "  - Newlines: 32\n",
      "  - Contains quotes: Yes\n",
      "\n",
      "First 300 chars of respuesta:\n",
      "\"Mi InformaciÃ³n Confidencial es una plataforma para el envÃ­o seguro de informaciÃ³n por medio de una clave que asignan clientes de Banco Davivienda (PN-PJ), Fiduciaria Davivienda S.A para el proceso de apertura de archivos o documentos.\n",
      "\n",
      "En el siguiente enlace puedes ingresar a mi  informaciÃ³n confid\n",
      "...\n",
      "\n",
      "âœ… ID 5475 FOUND\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Titulo: Â¿CuÃ¡les son los motivos de rechazo en Postillion?\n",
      "\n",
      "Respuesta stats:\n",
      "  - Length: 933 characters\n",
      "  - Newlines: 4\n",
      "  - Contains quotes: No\n",
      "\n",
      "First 300 chars of respuesta:\n",
      "EncontrarÃ¡s la lista completa de rechazos en Postillion en la presentaciÃ³n de capacitaciÃ³n del aplicativo FormaciÃ³n Call center - Postillion en el siguiente enlace https://drive.google.com/drive/folders/1JS0rXFJuSsuJKBbbf5CH-mbY5G4F3lzt \n",
      "\n",
      "Ten presente que la declinaciÃ³n 49 y 50 que aparecen como Res\n",
      "...\n",
      "\n",
      "âœ… ID 5181 FOUND\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Titulo: Â¿QuÃ© es y cÃ³mo se debe radicar un derecho de peticiÃ³n?\n",
      "\n",
      "Respuesta stats:\n",
      "  - Length: 4,698 characters\n",
      "  - Newlines: 60\n",
      "  - Contains quotes: No\n",
      "\n",
      "First 300 chars of respuesta:\n",
      "El derecho de peticiÃ³n es un derecho fundamental reconocido en la ConstituciÃ³n PolÃ­tica de Colombia y regulado por la ley 1755 del 2015, derecho que tiene toda persona a presentar peticiones respetuosas a las autoridades en los tÃ©rminos seÃ±alados en este cÃ³digo, por motivos de interÃ©s general o part\n",
      "...\n",
      "\n",
      "====================================================================================================\n",
      "ðŸŽ‰ SUCCESS! All 4/4 problematic IDs loaded correctly!\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Check specific problematic IDs\n",
    "problematic_ids = [588, 595, 5475, 5181]\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"VERIFICATION OF PROBLEMATIC RECORDS\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "found_count = 0\n",
    "for pid in problematic_ids:\n",
    "    matching_rows = df[df['idtbl_pregunta'] == pid]\n",
    "    if len(matching_rows) > 0:\n",
    "        found_count += 1\n",
    "        print(f\"\\nâœ… ID {pid} FOUND\")\n",
    "        print(\"-\" * 100)\n",
    "        row = matching_rows.iloc[0]\n",
    "        print(f\"Titulo: {row['titulo']}\")\n",
    "        print(f\"\\nRespuesta stats:\")\n",
    "        resp_text = str(row['respuesta'])\n",
    "        print(f\"  - Length: {len(resp_text):,} characters\")\n",
    "        print(f\"  - Newlines: {resp_text.count(chr(10))}\")\n",
    "        print(f\"  - Contains quotes: {'Yes' if '\"' in resp_text else 'No'}\")\n",
    "        print(f\"\\nFirst 300 chars of respuesta:\")\n",
    "        print(resp_text[:300])\n",
    "        print(\"...\")\n",
    "    else:\n",
    "        print(f\"\\nâŒ ID {pid} NOT FOUND\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "if found_count == len(problematic_ids):\n",
    "    print(f\"ðŸŽ‰ SUCCESS! All {found_count}/{len(problematic_ids)} problematic IDs loaded correctly!\")\n",
    "else:\n",
    "    print(f\"âš ï¸  Found {found_count}/{len(problematic_ids)} IDs\")\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Record Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "FULL RECORD DETAILS FOR ID 588\n",
      "====================================================================================================\n",
      "idtbl_pregunta: 588.0\n",
      "titulo: Â¿QuÃ© aspectos debo tener en cuenta para efectuar un ajuste por concepto de: GMF 4X1000, BRP, Uso de RPD y Egreso 25?\n",
      "\n",
      "respuesta:\n",
      "  Length: 6,066 chars\n",
      "  Newlines: 62\n",
      "  Preview (first 500 chars):\n",
      "GMF: Recordemos que todos los ajustes por GMF (4X1000) deben contar con el VoBo del Dpto de impuestos.Si el ajuste solicitado es autorizado la instrucciÃ³n del proceso, es decir, los conceptos y la forma en que se debe efectuar la transacciÃ³n de ajuste serÃ¡ dada por el dpto de impuestos exclusivamente.\n",
      "\n",
      "BRP: Los conceptos habilitados para el registro correcto de las operaciones de BRP son:\n",
      "\n",
      "1. DevoluciÃ³n cuota inicial BRP: DevoluciÃ³n de la cuota del BRP al cliente por cualquier concepto, Referenc...\n",
      "id_usuario_creador: 88.0\n",
      "fecha_creacion: 2020-01-24 00:00:00\n",
      "id_usuario_ultima_modificacion: 8036.0\n",
      "fecha_ultima_modificacion: 2025-10-03 11:45:40\n",
      "id_producto: 182.0\n",
      "id_estado: 6.0\n",
      "fecha_ult_actualizacion_keywords: 2025-04-22 19:00:00\n",
      "keywords_rag: ajuste, gmf, brp\n",
      "Vigencia: 2026-08-15 23:00:00\n",
      "estado_carga: 1.0\n",
      "dias_vigencia: nan\n",
      "justificacion_garante: Comentarios Similares: No existen contenidos similares.\n",
      "\n",
      "justificacion_curador: NULL\n",
      "publicado_workplace: NULL\n",
      "fecha_publicacion: 2025-08-15 08:00:00\n"
     ]
    }
   ],
   "source": [
    "# Show one complete problematic record (ID 588)\n",
    "if len(df[df['idtbl_pregunta'] == 588]) > 0:\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"FULL RECORD DETAILS FOR ID 588\")\n",
    "    print(\"=\" * 100)\n",
    "    record = df[df['idtbl_pregunta'] == 588].iloc[0]\n",
    "    for col in df.columns:\n",
    "        value = record[col]\n",
    "        if col == 'respuesta':\n",
    "            print(f\"\\n{col}:\")\n",
    "            print(f\"  Length: {len(str(value)):,} chars\")\n",
    "            print(f\"  Newlines: {str(value).count(chr(10))}\")\n",
    "            print(f\"  Preview (first 500 chars):\\n{str(value)[:500]}...\")\n",
    "        else:\n",
    "            print(f\"{col}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info\n",
    "print(\"DataFrame Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First few rows (with truncated respuesta for readability)\n",
    "display_df = df.head(10).copy()\n",
    "display_df['respuesta'] = display_df['respuesta'].str[:80] + '...'\n",
    "display_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate IDs\n",
    "duplicates = df[df.duplicated(subset=['idtbl_pregunta'], keep=False)]\n",
    "if len(duplicates) > 0:\n",
    "    print(f\"âš ï¸  Found {len(duplicates)} duplicate records:\")\n",
    "    print(duplicates[['idtbl_pregunta', 'titulo']].sort_values('idtbl_pregunta'))\n",
    "else:\n",
    "    print(\"âœ… No duplicate IDs found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze multiline content in respuesta\n",
    "df['_newline_count'] = df['respuesta'].astype(str).apply(lambda x: x.count('\\n'))\n",
    "df['_char_count'] = df['respuesta'].astype(str).apply(len)\n",
    "\n",
    "print(\"\\nMultiline content analysis:\")\n",
    "print(f\"Records with 0 newlines: {len(df[df['_newline_count'] == 0]):,}\")\n",
    "print(f\"Records with 1-10 newlines: {len(df[(df['_newline_count'] > 0) & (df['_newline_count'] <= 10)]):,}\")\n",
    "print(f\"Records with 11-50 newlines: {len(df[(df['_newline_count'] > 10) & (df['_newline_count'] <= 50)]):,}\")\n",
    "print(f\"Records with 50+ newlines: {len(df[df['_newline_count'] > 50]):,}\")\n",
    "\n",
    "print(f\"\\n\\nTop 10 records with most newlines:\")\n",
    "top_multiline = df.nlargest(10, '_newline_count')[['idtbl_pregunta', 'titulo', '_newline_count', '_char_count']]\n",
    "print(top_multiline.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"Total records: {len(df):,}\")\n",
    "print(f\"\\nDate range:\")\n",
    "print(f\"  Creation: {df['fecha_creacion'].min()} to {df['fecha_creacion'].max()}\")\n",
    "print(f\"  Last modified: {df['fecha_ultima_modificacion'].min()} to {df['fecha_ultima_modificacion'].max()}\")\n",
    "print(f\"\\nUnique products: {df['id_producto'].nunique()}\")\n",
    "print(f\"Unique states: {df['id_estado'].nunique()}\")\n",
    "\n",
    "print(f\"\\nRecords by estado_carga:\")\n",
    "print(df['estado_carga'].value_counts())\n",
    "\n",
    "print(f\"\\nRecords by id_estado:\")\n",
    "print(df['id_estado'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up Helper Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove temporary analysis columns\n",
    "df_clean = df.drop(['_newline_count', '_char_count'], axis=1, errors='ignore')\n",
    "print(f\"âœ… Cleaned dataframe has {len(df_clean.columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Export to Parquet (Recommended)\n",
    "\n",
    "Parquet format handles multiline text perfectly and is much more efficient than CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to save\n",
    "# df_clean.to_parquet('tbl_preguntas.parquet', index=False, engine='pyarrow')\n",
    "# print(\"âœ… Data saved to tbl_preguntas.parquet\")\n",
    "# print(\"\\nTo read back: df = pd.read_parquet('tbl_preguntas.parquet')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Export to properly formatted CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to save\n",
    "# import csv\n",
    "# df_clean.to_csv('tbl_preguntas_cleaned.csv', index=False, encoding='utf-8', \n",
    "#                 quoting=csv.QUOTE_ALL, escapechar=None, doublequote=True)\n",
    "# print(\"âœ… Cleaned data exported to tbl_preguntas_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 3: Export to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to save\n",
    "# df_clean.to_excel('tbl_preguntas.xlsx', index=False, engine='openpyxl')\n",
    "# print(\"âœ… Data saved to tbl_preguntas.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the Data\n",
    "\n",
    "Now you can use `df` or `df_clean` for your analysis. All problematic records are successfully loaded!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Search for questions containing specific keywords\n",
    "keyword = \"ajuste\"  # Change this to search for different keywords\n",
    "results = df_clean[df_clean['titulo'].str.contains(keyword, case=False, na=False)]\n",
    "print(f\"Found {len(results)} questions containing '{keyword}':\")\n",
    "results[['idtbl_pregunta', 'titulo']].head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
