{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2d4a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee93320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html_text(html_text):\n",
    "    \"\"\"\n",
    "    Limpia texto quwe contiene etiquetas HTML manteniendo saltos de línea <br> y enlaces.\n",
    "    Args:\n",
    "        html_text (str): Texto con etiquetas HTML\n",
    "    Returns:\n",
    "        str: Texto limpio con saltos de línea y enlaces preservados\n",
    "    \"\"\"\n",
    "    # Verificar si el valor es una cadena\n",
    "    if not isinstance(html_text, str):\n",
    "        return html_text\n",
    "\n",
    "    # Paso 1: Usar BeautifulSoup para manejar el HTML\n",
    "    soup = BeautifulSoup(html_text, \"html.parser\")\n",
    "\n",
    "    # Paso 2: Reemplazar <br> tags con un marcador especial\n",
    "    for br in soup.find_all(\"br\"):\n",
    "        br.replace_with(\"\\n\\n\")\n",
    "\n",
    "    # Paso 3: Procesar los enlaces de diversas etiquetas\n",
    "    tags_to_process = [\"a\", \"link\", \"iframe\", \"script\", \"img\", \"audio\", \"video\", \"area\"]\n",
    "    for tag_name in tags_to_process:\n",
    "        for tag in soup.find_all(tag_name):\n",
    "            # Obtener todos los atributos que podrían contener URLs\n",
    "            attributes = tag.attrs\n",
    "            for attr, value in attributes.items():\n",
    "                if isinstance(value, str) and (\n",
    "                    \"http://\" in value or \"https://\" in value\n",
    "                ):\n",
    "                    # Extraer y formatear los links\n",
    "                    try:\n",
    "                        if tag_name == \"a\":\n",
    "                            href = tag.get(\"href\", \"\")\n",
    "                            text = tag.get_text()\n",
    "                            if href and text:\n",
    "                                tag.replace_with(\n",
    "                                    f\" ({href})\"\n",
    "                                )  # Mantener el texto y agregar el link\n",
    "\n",
    "                        elif tag_name in (\n",
    "                            \"img\",\n",
    "                            \"script\",\n",
    "                            \"audio\",\n",
    "                            \"video\",\n",
    "                            \"iframe\",\n",
    "                            \"area\",\n",
    "                        ):\n",
    "                            if \"src\" in tag.attrs:\n",
    "                                tag.replace_with(f\" ({tag['src']})\")\n",
    "\n",
    "                        elif tag_name == \"link\":\n",
    "                            if \"href\" in tag.attrs:\n",
    "                                tag.replace_with(f\" ({tag['href']})\")\n",
    "                    except:\n",
    "                        tag.replace_with(f\" ({value})\")\n",
    "\n",
    "    # Paso 4: Obtener el texto\n",
    "    text = soup.get_text()\n",
    "\n",
    "    # Paso 5: Limpiar caracteres especiales y espacios múltiples (opcional, mantenido de tu código original)\n",
    "    # clean_text = re.sub(r\"\\s+\", \" \", text)  # Reemplazar múltiples espacios con uno solo\n",
    "    # clean_text = re.sub(r\"&nbsp;\", \" \", clean_text)  # Reemplazar &nbsp;\n",
    "\n",
    "    # Paso 6: Limpiar espacios al inicio y final manteniendo los saltos de línea internos\n",
    "    lines = text.split(\"\\n\")\n",
    "    clean_lines = [line.strip() for line in lines]\n",
    "    clean_text = \"\\n\\n\".join(filter(None, clean_lines))\n",
    "\n",
    "    return clean_text\n",
    "\n",
    "# Leer el archivo CSV\n",
    "df = df_fixed.copy()\n",
    "\n",
    "# Mostrar el número total de registros\n",
    "print(\"Total de registros antes de la limpieza:\", len(df))\n",
    "\n",
    "# Aplicar la función de limpieza a todas las columnas que contienen texto\n",
    "# columnas_texto = df.select_dtypes(include=[\"object\"]).columns\n",
    "# for columna in columnas_texto:\n",
    "#     df[columna] = df[columna].apply(clean_html_text)\n",
    "\n",
    "df['texto'] = df['texto'].apply(clean_html_text)\n",
    "\n",
    "print(\"\\nTotal de registros después de la limpieza:\", len(df))\n",
    "\n",
    "# Mostrar las primeras 3 filas del DataFrame limpio\n",
    "# print(\"\\nPrimeras 3 filas del DataFrame limpio:\")\n",
    "df.head(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
