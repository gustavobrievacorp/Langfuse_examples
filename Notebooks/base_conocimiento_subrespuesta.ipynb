{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# An√°lisis Base de Conocimiento - Subrespuesta y Segmento\n",
    "\n",
    "Este notebook procesa archivos de base de conocimiento:\n",
    "- `_tbl_subrespuesta__PRD_baseconocimientosdb_202511201112.json`\n",
    "- `_tbl_segmento__PRD_baseconocimientosdb_202511201112.json`\n",
    "\n",
    "Objetivos:\n",
    "1. Leer archivos JSON del ZIP\n",
    "2. Limpiar HTML de columnas 'texto'\n",
    "3. Cruzar por `id_pregunta` y consolidar textos\n",
    "4. Analizar campo `activo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import zipfile\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_load",
   "metadata": {},
   "source": [
    "## 1. Cargar archivos JSON desde ZIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_json_desde_zip(zip_path, archivos_objetivo):\n",
    "    \"\"\"\n",
    "    Carga archivos JSON espec√≠ficos desde un ZIP.\n",
    "    \n",
    "    Args:\n",
    "        zip_path (str): Ruta al archivo ZIP\n",
    "        archivos_objetivo (list): Lista de nombres de archivos JSON a buscar\n",
    "    \n",
    "    Returns:\n",
    "        dict: Diccionario con {nombre_archivo: DataFrame}\n",
    "    \"\"\"\n",
    "    dataframes = {}\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        archivos_disponibles = zip_ref.namelist()\n",
    "        print(f\"üì¶ Archivos en ZIP: {len(archivos_disponibles)}\")\n",
    "        for archivo in archivos_disponibles:\n",
    "            print(f\"   - {archivo}\")\n",
    "        \n",
    "        for archivo_objetivo in archivos_objetivo:\n",
    "            # Buscar archivo que contenga el nombre objetivo\n",
    "            archivo_encontrado = None\n",
    "            for archivo in archivos_disponibles:\n",
    "                if archivo_objetivo in archivo and archivo.endswith('.json'):\n",
    "                    archivo_encontrado = archivo\n",
    "                    break\n",
    "            \n",
    "            if not archivo_encontrado:\n",
    "                print(f\"\\n‚ö†Ô∏è  No encontrado: {archivo_objetivo}\")\n",
    "                dataframes[archivo_objetivo] = pd.DataFrame()\n",
    "                continue\n",
    "            \n",
    "            print(f\"\\nüìÑ Procesando: '{archivo_encontrado}'...\")\n",
    "            \n",
    "            try:\n",
    "                with zip_ref.open(archivo_encontrado, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    \n",
    "                    # Estructura: {\"SELECT * FROM tabla\": [{registro1}, {registro2}, ...]}\n",
    "                    if isinstance(data, dict):\n",
    "                        records = list(data.values())[0]\n",
    "                        df = pd.DataFrame(records)\n",
    "                        \n",
    "                        # Reemplazar null por pd.NA\n",
    "                        df = df.replace({None: pd.NA, 'null': pd.NA, 'NULL': pd.NA})\n",
    "                        \n",
    "                        print(f\"  ‚úì {len(df):,} registros cargados\")\n",
    "                        print(f\"  ‚úì Columnas: {list(df.columns)}\")\n",
    "                        \n",
    "                        # Informaci√≥n sobre 'texto' y 'activo'\n",
    "                        if 'texto' in df.columns:\n",
    "                            texto_no_vacio = df['texto'].notna().sum()\n",
    "                            print(f\"  ‚úì Registros con texto: {texto_no_vacio:,} ({texto_no_vacio/len(df)*100:.1f}%)\")\n",
    "                        \n",
    "                        if 'activo' in df.columns:\n",
    "                            print(f\"  ‚úì Distribuci√≥n activo:\")\n",
    "                            print(df['activo'].value_counts().to_string().replace('\\n', '\\n    '))\n",
    "                        \n",
    "                        dataframes[archivo_objetivo] = df\n",
    "                    else:\n",
    "                        print(f\"  ‚ö†Ô∏è  Formato inesperado: {type(data)}\")\n",
    "                        dataframes[archivo_objetivo] = pd.DataFrame()\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ùå Error: {e}\")\n",
    "                dataframes[archivo_objetivo] = pd.DataFrame()\n",
    "    \n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar archivos\n",
    "ZIP_PATH = '../_tbl_subrespuesta__PRD_baseconocimientosdb_202511201112.zip'\n",
    "\n",
    "ARCHIVOS_OBJETIVO = [\n",
    "    '_tbl_segmento',\n",
    "    '_tbl_subrespuesta'\n",
    "]\n",
    "\n",
    "dfs = cargar_json_desde_zip(ZIP_PATH, ARCHIVOS_OBJETIVO)\n",
    "\n",
    "df_segmento = dfs['_tbl_segmento']\n",
    "df_subrespuesta = dfs['_tbl_subrespuesta']\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"RESUMEN DE CARGA\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"df_segmento: {len(df_segmento):,} filas\")\n",
    "print(f\"df_subrespuesta: {len(df_subrespuesta):,} filas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_clean",
   "metadata": {},
   "source": [
    "## 2. Funci√≥n de limpieza de HTML\n",
    "\n",
    "### An√°lisis de la funci√≥n `clean_html_text`:\n",
    "\n",
    "**Puntos fuertes:**\n",
    "- ‚úÖ Usa BeautifulSoup para parsear HTML correctamente\n",
    "- ‚úÖ Preserva saltos de l√≠nea (`<br>`)\n",
    "- ‚úÖ Extrae URLs de m√∫ltiples tags\n",
    "- ‚úÖ Maneja casos donde el input no es string\n",
    "\n",
    "**Puntos de mejora identificados:**\n",
    "1. ‚ùå **C√≥digo repetitivo**: La l√≥gica de extracci√≥n de URLs se repite para cada tag\n",
    "2. ‚ùå **Try-except silencioso**: Captura excepciones sin logging, dificulta debug\n",
    "3. ‚ùå **L√≠neas comentadas**: C√≥digo muerto (l√≠neas 48-49) deber√≠a removerse\n",
    "4. ‚ùå **Par√°metros hardcodeados**: Separador `\\n\\n` no es configurable\n",
    "5. ‚ùå **No maneja listas/tablas HTML**: `<ul>`, `<ol>`, `<table>` no tienen formato especial\n",
    "6. ‚ö†Ô∏è  **Eficiencia**: Itera m√∫ltiples veces sobre tags en lugar de una sola pasada\n",
    "\n",
    "### Versi√≥n mejorada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean_function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html_text(html_text, preserve_links=True, line_separator='\\n\\n'):\n",
    "    \"\"\"\n",
    "    Limpia texto con etiquetas HTML manteniendo estructura legible.\n",
    "    \n",
    "    Mejoras sobre versi√≥n original:\n",
    "    - Par√°metros configurables (preserve_links, line_separator)\n",
    "    - Mejor manejo de listas (<ul>, <ol>, <li>)\n",
    "    - Logging de errores en lugar de try-except silencioso\n",
    "    - C√≥digo m√°s limpio y DRY\n",
    "    \n",
    "    Args:\n",
    "        html_text (str): Texto con etiquetas HTML\n",
    "        preserve_links (bool): Si True, preserva URLs entre par√©ntesis\n",
    "        line_separator (str): Separador para saltos de l√≠nea (default: '\\n\\n')\n",
    "    \n",
    "    Returns:\n",
    "        str: Texto limpio\n",
    "    \"\"\"\n",
    "    # Verificar tipo\n",
    "    if not isinstance(html_text, str):\n",
    "        return html_text\n",
    "    \n",
    "    if not html_text.strip():\n",
    "        return html_text\n",
    "    \n",
    "    try:\n",
    "        # Parsear HTML\n",
    "        soup = BeautifulSoup(html_text, \"html.parser\")\n",
    "        \n",
    "        # Reemplazar <br> con salto de l√≠nea\n",
    "        for br in soup.find_all(\"br\"):\n",
    "            br.replace_with(line_separator)\n",
    "        \n",
    "        # Agregar bullets a items de lista\n",
    "        for li in soup.find_all(\"li\"):\n",
    "            li.insert(0, \"‚Ä¢ \")\n",
    "            li.append(line_separator)\n",
    "        \n",
    "        # Agregar saltos despu√©s de p√°rrafos\n",
    "        for p in soup.find_all(\"p\"):\n",
    "            p.append(line_separator)\n",
    "        \n",
    "        # Procesar enlaces si preserve_links=True\n",
    "        if preserve_links:\n",
    "            # Tags y sus atributos que contienen URLs\n",
    "            url_tags = {\n",
    "                'a': 'href',\n",
    "                'img': 'src',\n",
    "                'script': 'src',\n",
    "                'audio': 'src',\n",
    "                'video': 'src',\n",
    "                'iframe': 'src',\n",
    "                'link': 'href',\n",
    "                'area': 'href'\n",
    "            }\n",
    "            \n",
    "            for tag_name, attr in url_tags.items():\n",
    "                for tag in soup.find_all(tag_name):\n",
    "                    url = tag.get(attr, '')\n",
    "                    if url and ('http://' in url or 'https://' in url):\n",
    "                        # Para enlaces <a>, preservar texto + URL\n",
    "                        if tag_name == 'a':\n",
    "                            text = tag.get_text().strip()\n",
    "                            if text:\n",
    "                                tag.replace_with(f\"{text} ({url})\")\n",
    "                            else:\n",
    "                                tag.replace_with(f\"({url})\")\n",
    "                        else:\n",
    "                            # Para otros tags, solo URL\n",
    "                            tag.replace_with(f\" ({url}) \")\n",
    "        \n",
    "        # Obtener texto limpio\n",
    "        text = soup.get_text()\n",
    "        \n",
    "        # Limpiar espacios m√∫ltiples en cada l√≠nea\n",
    "        lines = text.split('\\n')\n",
    "        clean_lines = [re.sub(r'\\s+', ' ', line.strip()) for line in lines]\n",
    "        \n",
    "        # Remover l√≠neas vac√≠as y unir\n",
    "        clean_text = line_separator.join(filter(None, clean_lines))\n",
    "        \n",
    "        # Limpiar entidades HTML restantes\n",
    "        clean_text = clean_text.replace('&nbsp;', ' ')\n",
    "        clean_text = clean_text.replace('&amp;', '&')\n",
    "        clean_text = clean_text.replace('&lt;', '<')\n",
    "        clean_text = clean_text.replace('&gt;', '>')\n",
    "        \n",
    "        return clean_text.strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        # En producci√≥n, usar logging en lugar de print\n",
    "        print(f\"‚ö†Ô∏è  Error limpiando HTML: {e}\")\n",
    "        print(f\"   Texto problem√°tico (primeros 100 chars): {str(html_text)[:100]}\")\n",
    "        return html_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_apply",
   "metadata": {},
   "source": [
    "## 3. Aplicar limpieza a columnas 'texto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apply_clean",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"APLICANDO LIMPIEZA DE HTML\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Aplicar a df_segmento\n",
    "print(\"\\nüìÑ Limpiando df_segmento...\")\n",
    "if 'texto' in df_segmento.columns:\n",
    "    df_segmento['texto_limpio'] = df_segmento['texto'].apply(clean_html_text)\n",
    "    print(f\"  ‚úì {len(df_segmento):,} registros procesados\")\n",
    "    \n",
    "    # Comparar antes/despu√©s\n",
    "    sample_idx = df_segmento[df_segmento['texto'].notna()].index[0]\n",
    "    print(f\"\\n  üìã Ejemplo de limpieza (registro {sample_idx}):\")\n",
    "    print(f\"  ANTES: {df_segmento.loc[sample_idx, 'texto'][:200]}...\")\n",
    "    print(f\"  DESPU√âS: {df_segmento.loc[sample_idx, 'texto_limpio'][:200]}...\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è  No hay columna 'texto' en df_segmento\")\n",
    "\n",
    "# Aplicar a df_subrespuesta\n",
    "print(\"\\nüìÑ Limpiando df_subrespuesta...\")\n",
    "if 'texto' in df_subrespuesta.columns:\n",
    "    df_subrespuesta['texto_limpio'] = df_subrespuesta['texto'].apply(clean_html_text)\n",
    "    print(f\"  ‚úì {len(df_subrespuesta):,} registros procesados\")\n",
    "    \n",
    "    # Comparar antes/despu√©s\n",
    "    sample_idx = df_subrespuesta[df_subrespuesta['texto'].notna()].index[0]\n",
    "    if pd.notna(df_subrespuesta.loc[sample_idx, 'texto']):\n",
    "        print(f\"\\n  üìã Ejemplo de limpieza (registro {sample_idx}):\")\n",
    "        print(f\"  ANTES: {df_subrespuesta.loc[sample_idx, 'texto'][:200]}...\")\n",
    "        print(f\"  DESPU√âS: {df_subrespuesta.loc[sample_idx, 'texto_limpio'][:200]}...\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è  No hay columna 'texto' en df_subrespuesta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_merge",
   "metadata": {},
   "source": [
    "## 4. Cruzar bases por id_pregunta y consolidar textos\n",
    "\n",
    "Estrategia:\n",
    "1. Hacer **outer join** por `id_pregunta` para capturar registros de ambas bases\n",
    "2. Consolidar todos los textos de cada `id_pregunta` en un solo campo\n",
    "3. Analizar campo `activo` en los cruces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "merge",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CRUCE DE BASES POR id_pregunta\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Preparar dataframes para el merge\n",
    "# Agregar sufijos para identificar origen\n",
    "df_merged = pd.merge(\n",
    "    df_segmento,\n",
    "    df_subrespuesta,\n",
    "    on='id_pregunta',\n",
    "    how='outer',\n",
    "    suffixes=('_segmento', '_subrespuesta')\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Resultados del merge:\")\n",
    "print(f\"  Total registros despu√©s del merge: {len(df_merged):,}\")\n",
    "print(f\"  id_pregunta √∫nicos: {df_merged['id_pregunta'].nunique():,}\")\n",
    "\n",
    "# Analizar origen de registros\n",
    "solo_segmento = df_merged['idtbl_segmento'].notna() & df_merged['idtbl_subrespuesta'].isna()\n",
    "solo_subrespuesta = df_merged['idtbl_segmento'].isna() & df_merged['idtbl_subrespuesta'].notna()\n",
    "en_ambas = df_merged['idtbl_segmento'].notna() & df_merged['idtbl_subrespuesta'].notna()\n",
    "\n",
    "print(f\"\\nüìã Distribuci√≥n por origen:\")\n",
    "print(f\"  Solo en df_segmento: {solo_segmento.sum():,} registros\")\n",
    "print(f\"  Solo en df_subrespuesta: {solo_subrespuesta.sum():,} registros\")\n",
    "print(f\"  En ambas bases: {en_ambas.sum():,} registros\")\n",
    "\n",
    "# Consolidar textos por id_pregunta\n",
    "print(f\"\\nüîÑ Consolidando textos por id_pregunta...\")\n",
    "\n",
    "def consolidar_textos(row):\n",
    "    \"\"\"\n",
    "    Consolida textos de segmento y subrespuesta en un solo texto.\n",
    "    \"\"\"\n",
    "    textos = []\n",
    "    \n",
    "    # Texto de segmento\n",
    "    if pd.notna(row.get('texto_limpio_segmento')):\n",
    "        texto_seg = str(row['texto_limpio_segmento']).strip()\n",
    "        if texto_seg:\n",
    "            textos.append(f\"[SEGMENTO] {texto_seg}\")\n",
    "    \n",
    "    # Texto de subrespuesta\n",
    "    if pd.notna(row.get('texto_limpio_subrespuesta')):\n",
    "        texto_sub = str(row['texto_limpio_subrespuesta']).strip()\n",
    "        if texto_sub:\n",
    "            textos.append(f\"[SUBRESPUESTA] {texto_sub}\")\n",
    "    \n",
    "    return '\\n\\n'.join(textos) if textos else pd.NA\n",
    "\n",
    "df_merged['texto_consolidado'] = df_merged.apply(consolidar_textos, axis=1)\n",
    "\n",
    "# Estad√≠sticas de consolidaci√≥n\n",
    "registros_con_texto = df_merged['texto_consolidado'].notna().sum()\n",
    "print(f\"  ‚úì Registros con texto consolidado: {registros_con_texto:,} ({registros_con_texto/len(df_merged)*100:.1f}%)\")\n",
    "\n",
    "# Mostrar ejemplo\n",
    "ejemplo = df_merged[df_merged['texto_consolidado'].notna()].iloc[0]\n",
    "print(f\"\\n  üìã Ejemplo de texto consolidado (id_pregunta={ejemplo['id_pregunta']}):\")\n",
    "print(f\"  {ejemplo['texto_consolidado'][:500]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_activo",
   "metadata": {},
   "source": [
    "## 5. An√°lisis del campo 'activo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze_activo",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"AN√ÅLISIS DEL CAMPO 'activo'\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# An√°lisis general\n",
    "print(\"\\nüìä Distribuci√≥n de 'activo' en cada base:\")\n",
    "print(\"\\ndf_segmento:\")\n",
    "if 'activo_segmento' in df_merged.columns:\n",
    "    print(df_merged['activo_segmento'].value_counts(dropna=False).to_string())\n",
    "\n",
    "print(\"\\ndf_subrespuesta:\")\n",
    "if 'activo_subrespuesta' in df_merged.columns:\n",
    "    print(df_merged['activo_subrespuesta'].value_counts(dropna=False).to_string())\n",
    "\n",
    "# An√°lisis de cruces\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"AN√ÅLISIS DE CRUCES (registros presentes en AMBAS bases)\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "df_cruces = df_merged[en_ambas].copy()\n",
    "print(f\"\\nTotal de cruces: {len(df_cruces):,} registros\")\n",
    "\n",
    "if len(df_cruces) > 0:\n",
    "    # Crear categor√≠as de an√°lisis\n",
    "    df_cruces['categoria_activo'] = 'Otro'\n",
    "    \n",
    "    # Ambos activo=1\n",
    "    ambos_activos = (df_cruces['activo_segmento'] == 1) & (df_cruces['activo_subrespuesta'] == 1)\n",
    "    df_cruces.loc[ambos_activos, 'categoria_activo'] = 'Ambos activo=1'\n",
    "    \n",
    "    # Ambos activo=0\n",
    "    ambos_inactivos = (df_cruces['activo_segmento'] == 0) & (df_cruces['activo_subrespuesta'] == 0)\n",
    "    df_cruces.loc[ambos_inactivos, 'categoria_activo'] = 'Ambos activo=0'\n",
    "    \n",
    "    # Solo segmento activo\n",
    "    solo_seg_activo = (df_cruces['activo_segmento'] == 1) & (df_cruces['activo_subrespuesta'] == 0)\n",
    "    df_cruces.loc[solo_seg_activo, 'categoria_activo'] = 'Solo segmento activo=1'\n",
    "    \n",
    "    # Solo subrespuesta activo\n",
    "    solo_sub_activo = (df_cruces['activo_segmento'] == 0) & (df_cruces['activo_subrespuesta'] == 1)\n",
    "    df_cruces.loc[solo_sub_activo, 'categoria_activo'] = 'Solo subrespuesta activo=1'\n",
    "    \n",
    "    # Resumen\n",
    "    print(\"\\nüìã Distribuci√≥n de estados 'activo' en cruces:\")\n",
    "    resumen = df_cruces['categoria_activo'].value_counts()\n",
    "    for categoria, count in resumen.items():\n",
    "        porcentaje = count / len(df_cruces) * 100\n",
    "        print(f\"  {categoria}: {count:,} ({porcentaje:.1f}%)\")\n",
    "    \n",
    "    # Insight clave\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"INSIGHTS CLAVE\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    if ambos_activos.sum() == len(df_cruces):\n",
    "        print(\"‚úÖ Todos los cruces tienen activo=1 en ambas bases (consistencia perfecta)\")\n",
    "    elif ambos_inactivos.sum() == len(df_cruces):\n",
    "        print(\"‚ö†Ô∏è  Todos los cruces tienen activo=0 en ambas bases\")\n",
    "    else:\n",
    "        inconsistencias = solo_seg_activo.sum() + solo_sub_activo.sum()\n",
    "        porc_incons = inconsistencias / len(df_cruces) * 100\n",
    "        print(f\"‚ö†Ô∏è  Hay {inconsistencias:,} cruces ({porc_incons:.1f}%) con valores diferentes de 'activo'\")\n",
    "        print(f\"    Esto podr√≠a indicar desincronizaci√≥n entre las bases\")\n",
    "    \n",
    "    # Tabla resumen\n",
    "    print(\"\\nüìä Tabla de contingencia (segmento x subrespuesta):\")\n",
    "    contingencia = pd.crosstab(\n",
    "        df_cruces['activo_segmento'],\n",
    "        df_cruces['activo_subrespuesta'],\n",
    "        margins=True,\n",
    "        margins_name='TOTAL'\n",
    "    )\n",
    "    contingencia.index.name = 'activo_segmento'\n",
    "    contingencia.columns.name = 'activo_subrespuesta'\n",
    "    print(contingencia)\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No hay registros que crucen en ambas bases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_export",
   "metadata": {},
   "source": [
    "## 6. Exportar resultados consolidados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame final consolidado por id_pregunta\n",
    "df_consolidado_final = df_merged.groupby('id_pregunta').agg({\n",
    "    'texto_consolidado': lambda x: '\\n\\n---\\n\\n'.join(x.dropna()),\n",
    "    'activo_segmento': lambda x: x.mode()[0] if len(x.mode()) > 0 else pd.NA,\n",
    "    'activo_subrespuesta': lambda x: x.mode()[0] if len(x.mode()) > 0 else pd.NA,\n",
    "    'titulo_segmento': 'first',\n",
    "    'titulo_subrespuesta': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"\\nüì¶ DataFrame consolidado final:\")\n",
    "print(f\"  {len(df_consolidado_final):,} id_pregunta √∫nicos\")\n",
    "print(f\"\\nPrimeras 5 filas:\")\n",
    "print(df_consolidado_final.head())\n",
    "\n",
    "# Opcional: Exportar a CSV\n",
    "# df_consolidado_final.to_csv('../Salidas/base_conocimiento_consolidada.csv', index=False)\n",
    "# print(\"\\n‚úÖ Exportado a: ../Salidas/base_conocimiento_consolidada.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
